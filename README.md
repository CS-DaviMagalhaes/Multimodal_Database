# Multimodal_Database

Sistema de Base de Datos Multimodal con Indexaci√≥n Avanzada

## üß† Backend (FastAPI)

Este backend simula un sistema de base de datos que interpreta consultas SQL b√°sicas (`CREATE TABLE`, `INSERT`, `SELECT`, `CREATE INDEX`) y las ejecuta sobre archivos binarios. Usa una estructura de almacenamiento personalizada junto con algoritmos de √≠ndices como B+ Tree, con soporte planificado para AVL y secuencial.

### üîß Funcionalidades implementadas:

- **CREATE TABLE**: 
  - Guarda la estructura de la tabla en un archivo `.meta` dentro de `/tablas/`.
  - Crea un archivo `.tbl` binario para almacenar los registros.

- **INSERT INTO**:
  - Inserta datos en el archivo binario correspondiente.
  - Valida claves primarias si est√°n definidas.
  - Si existen √≠ndices para las columnas, los actualiza autom√°ticamente.

- **CREATE INDEX**:
  - Soporte actual para √≠ndice `BPLUS`, pronto para `AVL` y `SEQUENTIAL`.
  - Crea un archivo `.idx` en `/indices/` con estructura binaria.
  - Permite usar estructuras de √°rbol para b√∫squedas r√°pidas.

- **SELECT**:
  - Soporta:
    - `SELECT * FROM tabla`
    - `SELECT columna1, columna2 FROM tabla`
    - `SELECT ... WHERE columna = valor`
    - `SELECT ... WHERE columna BETWEEN valor1 AND valor2`
  - Si hay √≠ndice creado en la columna usada en `WHERE`, se utiliza autom√°ticamente para optimizar el acceso (usa `search` o `rangeSearch`).
  - Si no hay √≠ndice, la b√∫squeda es secuencial.

### üìÇ Organizaci√≥n de archivos:

| Carpeta     | Contenido                          |
|-------------|------------------------------------|
| `tablas/`   | `.meta` y `.tbl` por cada tabla    |
| `indices/`  | Archivos `.idx` por √≠ndice creado  |
| `algoritmos/` | Implementaciones de √≠ndices       |

### üîê Estructuras de archivo:

- Header del archivo `.idx`: contiene info sobre posici√≥n root, libres, eliminados.
- Registro binario `.tbl`: estructurado con `struct.pack` seg√∫n tipos definidos en `.meta`.

---

## üñ•Ô∏è Frontend (React)

Este frontend es una interfaz web simple para interactuar con el backend simulando una consola SQL. Permite enviar consultas manuales y visualizar resultados en tiempo real.

### ‚ú® Caracter√≠sticas:

- **Textarea para consultas SQL**:
  - Env√≠a la consulta como JSON al backend (`POST /query`)
  - Compatible con todos los comandos mencionados

- **Autocompletado b√°sico**:
  - Sugiere palabras clave SQL (`SELECT`, `WHERE`, etc.)
  - Tambi√©n sugiere nombres de tablas y columnas conocidas
  - Inserta autom√°ticamente la palabra seleccionada

- **Visualizaci√≥n de resultados**:
  - Si el resultado es un `SELECT`, se renderiza una tabla HTML con los datos.
  - El resultado crudo (JSON) tambi√©n se muestra debajo como referencia t√©cnica.

- **Bot√≥n adicional "Ver registros"**:
  - Llama directamente al endpoint `GET /select/{tabla}` para obtener todos los registros (b√∫squeda secuencial).

### üß© Estado del frontend:

- Interfaz responsiva y f√°cil de extender
- Backend y frontend conectados por defecto en `http://localhost:3000` ‚Üî `http://localhost:8000`

---







## Dataset
Utilizamos el dataset `cities` que tiene `148061` registros con los siguientes atributos: 
- `id`: id de la ciudad
- `name`: nombre de la ciudad
- `state_id`: id del estado
- `state_code`: c√≥digo del estado
- `state_name`: nombre del estado
- `country_id`: id del pa√≠s
- `country_code`: c√≥digo del pa√≠s
- `country_name`: nombre del pa√≠s
- `latitude`: coordenada latitud
- `longitude`: coordenada longitud
- `wikiDataId`: id de la ciudad registrado en wikidata.org

---

## Extendible Hashing

Extendible Hashing que mantiene el √≠ndice en RAM y los buckets en disco, permitiendo inserciones, b√∫squedas, splits y overflows de forma eficiente.

### Estrategias utilizadas en la implementaci√≥n

### Estructura general
Mientras estamos trabajando sobre el archivo del √≠ndice lo almacenamos en RAM para poder hacer operaciones de forma m√°s eficiente. Cada cambio hecho al
√≠ndice en RAM tambi√©n se hace al archivo del √≠ndice, as√≠ podemos tenerlo en disco y abrirlo nuevamente despu√©s. Por ejemplo el √≠ndice para 1 mill√≥n de
datos con `32768` entradas pesa menos de `1MB`.

Se tiene un factor de balanceo `fb` que indica la cantidad de registros por bucket y una profundidad global `D` para poder manejar los splits.

Los buckets se construyen sobre el mismo archivo `data.bin`. Para cada bucket tenemos un header que almacena lo siguiente: 
- El n√∫mero del bucket en decimal `bucket_id`
- La profundidad local `d`
- El siguiente bucket de overflow `next`
- La cantidad de registros no vac√≠os en el bucket `size`
- fb registros que se inicializan como registros en blanco

Reservamos fb registros para cada bucket. Simplemente esos registros son el constructor por defecto `Registro()`, representando un registro vac√≠o. Cada vez que se inserta sobreescribimos esos registros y actualizamos el size del bucket, la cantidad de registros no vac√≠os.

### Search
Se implement√≥ la funci√≥n `get_reg_attributes()` que la b√∫squeda de un elemento en los buckets principales y overflow. Retorna el registro encontrado en
la b√∫squeda (si existe), la posici√≥n del registro y el n√∫mero del bucket. As√≠ podemos simplemente reutilizar esta funci√≥n en `search()` y `remove()`. El 
registro encontrado lo usamos en la b√∫squeda y los otros dos valores del retorno usamos en el m√©todo de borrado para poder acceder directamente al registro
y bucket asociado. As√≠ evitamos repetir c√≥digo.

### Remove y reconstrucci√≥n
La estrat√©gia de borrado que utilizamos es la siguiente: 
- Simplemente reemplazamos el registro que queremos borrar por un "registro vac√≠o" (constructor por defecto de `Registro()`).
- Contamos la cantidad de buckets vac√≠os (sin registros reales).
- Si la cantidad de buckets vac√≠os sobrepasa a los 40% hacemos una reconstrucci√≥n total del √≠ndice y de los buckets.

### Insert
Aplicamos hash al id numerico de los registros. Simplemente se inserta en el primer espacio vac√≠o que se encuentra del bucket correspondiente a ese hash. 
As√≠ reutilizamos los espacios que fueron borrados en remove. Si la profundidad local del bucket es menor a la profundidad global hacemos split en caso el
bucket est√© lleno. En caso ya no se pueda hacer split creamos buckets de overflow y los encadenamos.

### Experimentaci√≥n y Resultados
Para la experimentaci√≥n variamos los par√°metros `fb` y `D` para poder tener una distribuci√≥n de registros y un √≠ndice balanceado, ya que las pruebas var√≠an
en la cantidad de datos. As√≠ logramos tener tiempos eficientes para inserci√≥n, b√∫squeda y borrado. Utilizamos los siguientes valores:

| Registros | fb  | D  |
|-----------|-----|----|
| 1k        | 4   | 8  |
| 10k       | 6   | 10 |
| 100k      | 6   | 10 |
| 250k      | 10  | 12 |
| 500k      | 16  | 14 |
| 1M        | 18  | 15 |

Con estos par√°metros obtuvimos la siguiente cantidad de buckets y entradas en el √≠ndice: 
![Cantidad de buckets vs entradas √≠ndice](./imgs/num_buckets_and_entries.png)

### Insert
Hicimos la inserci√≥n de acuerdo a los valores de `fb` y `D` en la tabla de arriba:

![Insert](./imgs/insert_hash.png)


### Search
Hicimos la b√∫squeda de 100 keys aleatorios del dataset y sacamos el promedio: 

![Insert](./imgs/search_hash.png)

### Remove
Hicimos el borrado de 100 keys aleatorios del dataset y sacamos el promedio: 

![Remove](./imgs/remove_hash.png)

---

## ISAM

La implementaci√≥n del sistema de acceso secuencial indexado (ISAM) se dise√±√≥ con el objetivo de simular un sistema de archivos jer√°rquico eficiente, con soporte para inserci√≥n, b√∫squeda y eliminaci√≥n. A continuaci√≥n se detallan las estrategias clave empleadas:

### 1. Estructura Multinivel
Se utiliz√≥ una estructura jer√°rquica de dos niveles de indexaci√≥n:
- **Root Index (`root_index.bin`)**: Apunta a p√°ginas del √≠ndice intermedio.
- **Index Pages (`index_pages.bin`)**: Contienen referencias a p√°ginas de datos.
- **Data Pages (`data_pages.bin`)**: Almacenan los registros ordenados de forma secuencial.

Esto permite b√∫squedas logar√≠tmicas y navegaci√≥n eficiente por los niveles del √≠ndice.

### 2. Segmentaci√≥n por Archivos
Cada nivel de la estructura se almacena en un archivo binario independiente:
- `root_index.bin`
- `index_pages.bin`
- `data_pages.bin`
- `overflow.bin` (para las inserciones que no se pudieron hacer en el √°rea principal)

Esta segmentaci√≥n facilita el manejo modular del almacenamiento y el acceso por niveles.

### 3. Bloques con Factor Fijo
Se utiliz√≥ un **factor de bloqueo fijo**:
- `BLOCK_FACTOR_DATA = 5`: N√∫mero m√°ximo de registros por p√°gina de datos.
- `BLOCK_FACTOR_INDEX = 4`: N√∫mero m√°ximo de entradas por p√°gina de √≠ndice.

Esto asegura una estructura uniforme de p√°ginas, facilita el c√°lculo de offsets y permite navegaci√≥n por saltos fijos.

### 4. Registros Fijos y Serializaci√≥n con `struct`
Todos los registros (`Registro`) e √≠ndices (`IndexEntry`) se serializan usando el m√≥dulo `struct`, con un formato fijo (`FORMAT`) que asegura un tama√±o constante en disco. Esto permite:
- C√°lculo directo de posiciones (offsets) sin recorrer todo el archivo.
- Acceso eficiente a cualquier p√°gina o registro.

### 5. √Årea de Desborde (`overflow.bin`)
Las inserciones no se hacen en las p√°ginas de datos (por la naturaleza est√°tica del ISAM), sino que se redirigen a un archivo de desborde. Esto mantiene el √°rea principal inalterada y permite realizar operaciones de inserci√≥n sin reorganizar el √≠ndice.

### 6. B√∫squeda Binaria Aproximada por Niveles
Para cada b√∫squeda:
1. Se localiza la p√°gina adecuada en `root_index.bin`.
2. Luego se baja a la p√°gina de √≠ndice correspondiente.
3. Finalmente se accede a la p√°gina de datos que contiene o deber√≠a contener el registro.
4. Si no se encuentra, se busca en el `overflow.bin`.

Esta estrategia imita el comportamiento real del ISAM y permite realizar b√∫squedas eficientes con costo O(log n) en el mejor caso.

### 7. Lectura y Escritura P√°gina por P√°gina
Para mejorar la eficiencia y evitar acceso por registro, se leen y escriben bloques completos (p√°ginas) en lugar de registros individuales.

---
## Sequential File

La implementaci√≥n del Sequential File se dise√±√≥ para que trabaje en un solo archivo (sin metadata) con cabezera, usando las t√©cnicas del espacio auxiliar y linked records.

#### Espacio auxiliar 

El archivo esta dividido en dos partes: la p√°gina principal y el espacio auxiliar. En este √∫ltimo es donde se ir√°n insertando los registros hasta llegar a un *threshold* ($O(n)$ donde $n$ es la cantidad de registros en la p√°gina principal). 

Una vez alcanzado, reconstruiremos la p√°gina principal, donde se reorganizar√°n todos los registros (incluyendo los del espacio auxiliar) ordenados por una key predeterminada por el usuario.

El prop√≥sito de este dise√±o es para resolver el problema de desborde de espacio, as√≠ como ahorrarse las complejidades de mantener ordenados todos los registros constantemente.

#### Linked records

Para hacer m√°s f√°cil la preservaci√≥n de orden, se agreg√≥ un campo *next* a cada uno de los registros, que almacena la posici√≥n f√≠sica del siguiente registro seg√∫n el orden l√≥gico del archivo (determinado por una *key*).

Esta decisi√≥n trivializa las operaciones de borrado, donde solo desenlazamos el registro a eliminar, liberando su espacio para la siguiente reconstrucci√≥n.

### 1. Inserci√≥n

En nuestra implementaci√≥n, la inserci√≥n ocurre dentro del espacio auxiliar, donde se apilan los registros. Con cada inserci√≥n actualizamos el conteo de registros en la cabezera. Si dicha inserci√≥n activa una alerta de desborde, entonces se reconstruye el archivo, limpiando el espacio auxiliar.

Descontando el coste de reconstrucci√≥n, las inserciones cuenta con complejidad $O(1)$.

### 2. B√∫squeda singular

El dise√±o de la implementaci√≥n le otorga al *sequential file* la capacidad de b√∫squedas binarias bajo una *key*. Este tipo de b√∫squedas se caracterizan por ser el tipo de b√∫squeda m√°s eficiente, puesto que cuenta con complejidad de apenas $O(\log n)$.

Para optimizarla a√∫n m√°s, se utiliz√≥ la librer√≠a ```bisect``` de Python, lo que nos garantiza b√∫squedas veloces.

### 3. B√∫squeda por rango

Para las b√∫squedas por rango, se aplicaron dos b√∫squedas binarias para ubicar las posiciones del elemento iniclal y final del rango. Una vez encontrado, solo se recorr√≠a dicho rango se forma linear.

Este dise√±o nos da una complejidad $O(\log n)$ para las b√∫queda de los √≠ndices y $O(m)$ para recorrer el rango. Asumiendo que $m < n \to m \approx \log n$, nos da una complejidad final de $O(\log n)$.

### 4. Borrado

Como se mencion√≥ anteriormente, el borrado consiste en desenlazar el registro, uniendo el registro anterior con el siguiente seg√∫n el orden l√≥gico del archivo. Sin embargo, no se cont√≥ con agregar un atributo *prev* para guardar la posici√≥n del archivo anterior, lo que impide hacer uso de una b√∫squeda binaria para ubicar el registro a borrar.

Por lo tanto, se emple√≥ una b√∫squeda sequencial sobre el archivo, almacenando la posici√≥n del registro anterior hasta encontar el registro correcto. Una vez ubicado, se desenlaza a trav√©s del campo *next* de cada registro.

Este dise√±o nos da un costo $O(n)$ del borrado en el peor de los casos.

### Experimentaci√≥n y resultados

Para la fase de experimentaci√≥n de este √≠ndice, se utiliz√≥ un slice del dataset *cities* de distintos tama√±os $(1000, 5000, 1k, 15k, 20k, 25k, 30k)$ y se determin√≥ como llave al ```id``` de los registros. Se analizaron los tiempos de ejecuci√≥n de cada uno de los m√©todos para cada tama√±o del dataset, con el fin de analizar su rendimiento.

#### Inserci√≥n

![insert_seq](./imgs/insert_seq.png)

#### Search

Se aplic√≥ un ```search()``` a 100 elementos aleatorios, promediando el tiempo final.

![search_seq](./imgs/search_seq.png)

#### Range Search (rango de tama√±o 100)

![range_seq](./imgs/rangesearch_seq.png)

#### Borrado

Se aplic√≥ un ```remove()``` a 100 elementos aleatorios, promediando el tiempo final.

![remove_seq](./imgs/remove_seq.png)

---

## RTree

Para la implementaci√≥n del √≠ndice *RTree*, se dise√±√≥ para desacoplarlo del archivo principal, siendo este √≠ndice almacenado en m√∫ltiples archivos metadata, y se utiliz√≥ principalmente la librer√≠a ```rtree``` de Python.

El archivo principal solo se encargar√≠a de apilar los registros, siendo una interfaz para el √≠ndice *RTree*. Para manejar los borrados, cuenta con una *free list* almacenada en otro archivo aparte.

#### Librer√≠a ```rtree```

Esta librer√≠a aport√≥ con la implementaci√≥n de la estructura de datos, as√≠ como sus m√©todos para las inserciones, queries y borrados. Cuenta con m√©todos para almacenarse en memoria secundaria a trav√©s de archivos ```.rtree.dat``` y ```.rtree.idx```. Sin embargo, esta librer√≠a contaba con limitaciones que requer√≠an el uso de un archivo metadata personalizado para este proyecto:

- No maneja puntos, por lo que cada registro fue insertado como un rect√°ngulo de area 0.
- La llave de cada una de las hojas requer√≠an un orden incremental, por lo que se utiliz√≥ la posici√≥n de cada registro en el archivo principal en lugar de su *id*.
- No cuenta con m√©todos para b√∫squedas por radio. 

#### Metadata

Se cre√≥ un archivo Metadata que almacenaba los campos necesarios de cada registro para los m√©todos del *RTree* (como posici√≥n, longitud, latitud). Principalmente usado por la b√∫squeda radial y el borrado.

### M√©todos

Gracias a la librer√≠a, la implementaci√≥n de los m√©todos del *RTree* consisti√≥ en convertir los hiperpar√°metros en los adecuados para ejecutar el correspondiente del ```rtree```. Solo dos m√©todos necesitaron de l√≥gica extra para su correcto funcionamiento:

- ```radius_search((x, y), r)```: se realiz√≥ una query sobre el rect√°ngulo definido por los puntos $(x-r, y-r)$ y $(x+r, y+r)$.
Una vez obtenidos los registros extra√≠dos, se filtraron aquellos que exced√≠an su distancia hacia el centro $(x, y)$ calculado con la distancia euclidiana.
- ```erase(pos)```: usando la *metadata*, se obten√≠an las coordenadas *lon* y *lat* del registro, puesto que ```rtree``` no elimina elementos definidos por la *key*, sino que tamb√≠en necesita de sus coordenadas.

Tanto la inserci√≥n como la b√∫squeda por rect√°ngulo y la b√∫squeda KNN fueron interfaces de los m√©todos ```insert(rectangle)```, ```intersects(rectangle)``` y ```nearest(rectangle, k)``` del ```rtree```, siendo los puntos pasados como rect√°ngulos de √°rea 0.

### Experimentaci√≥n y resultados

Para la fase de experimentaci√≥n de este √≠ndice, se utiliz√≥ un slice del dataset *cities* de distintos tama√±os $(1000, 5000, 1k, 15k, 20k, 25k, 30k)$. Se analizaron los tiempos de ejecuci√≥n de cada uno de los m√©todos para cada tama√±o del dataset, con el fin de analizar su rendimiento.

#### Inserci√≥n

![insert_rtree](./imgs/insert_rtree.png)

#### Box Query

![box_rtree](./imgs/box_rtree.png)

#### Radial Query

![radial_rtree](./imgs/radial_rtree.png)

#### 100-Nearest Neighbors

![knn_rtree](./imgs/knn_rtree.png)

#### Borrado

Se aplic√≥ un ```remove()``` a 100 elementos aleatorios, promediando el tiempo final.

![remove_rtree](./imgs/remove_rtree.png)

---

## B+ Index
Con el objetivo de mejorar la eficiencia en las b√∫squedas sobre archivos de datos, se implement√≥ un √≠ndice basado en un √°rbol B+ no agrupado (unclustered). Esta estructura permite mantener las claves ordenadas y enlazadas en nodos hoja, mientras que los datos reales se almacenan en un archivo separado. Las hojas contienen punteros a la posici√≥n f√≠sica del registro en el archivo de datos.

Adem√°s, cada nodo hoja mantiene un campo next que enlaza con la siguiente hoja, lo que permite recorridos eficientes y b√∫squedas por rango. El √°rbol maneja claves de tipo int o string (hasta 30 caracteres), seg√∫n el par√°metro de configuraci√≥n.

La estructura est√° respaldada por un archivo binario que almacena los nodos, con una cabecera que contiene:

Posici√≥n del nodo ra√≠z

Posici√≥n libre (para insertar nuevos nodos)

Posici√≥n del nodo eliminado (para reutilizaci√≥n de espacio)

### 1. Inserci√≥n
La inserci√≥n sigue el recorrido t√≠pico del √°rbol B+, localizando la hoja adecuada para insertar la nueva clave. Si la hoja tiene espacio, se inserta ordenadamente. En caso de desbordamiento, se realiza una divisi√≥n (split) del nodo y se propaga hacia arriba si es necesario, manteniendo la altura m√≠nima del √°rbol.

Cada clave insertada en una hoja se enlaza con una posici√≥n exacta en el archivo de datos, actuando como √≠ndice secundario.

La complejidad de inserci√≥n es $O(\log n)$, correspondiente a la altura del √°rbol.

### 2. B√∫squeda singular
Para realizar b√∫squedas puntuales, el √≠ndice recorre desde la ra√≠z hasta una hoja aplicando comparaci√≥n binaria en cada nodo para determinar el hijo correspondiente. Una vez en la hoja, se verifica si la clave existe y se retorna la posici√≥n del registro en el archivo de datos.

Este dise√±o garantiza una complejidad de b√∫squeda $O(\log n)$.

### 3. B√∫squeda por rango
Gracias a que las hojas est√°n enlazadas mediante el campo next, la b√∫squeda por rango es eficiente. Primero, se localiza la primera clave del rango mediante b√∫squeda est√°ndar. Luego, se recorren las hojas sucesivas mientras las claves est√©n dentro del rango.

Este dise√±o ofrece complejidad $O(\log n)$ para ubicar el inicio del rango y $O(m)$ para recorrer $m$ claves dentro del mismo. Bajo el supuesto de que $m \approx \log n$, la complejidad se mantiene en $O(\log n)$.

### 4. Borrado
Actualmente, el √≠ndice no implementa una operaci√≥n de borrado. Sin embargo, se ha considerado la gesti√≥n del espacio libre mediante un campo de posici√≥n eliminada en la cabecera, pensado para futuras extensiones que permitan reutilizar nodos liberados.

### Experimentaci√≥n y resultados
Para evaluar el rendimiento de nuestro √≠ndice B+, se realizaron pruebas de inserci√≥n sobre un subconjunto del dataset cities, usando distintos valores del orden del √°rbol m (5, 10 , 25 y 100). Cada configuraci√≥n fue evaluada registrando el tiempo total de inserci√≥n y el tama√±o final del archivo generado.

Los resultados fueron los siguientes:

m = 5: Tiempo de inserci√≥n = 36 segundos, Tama√±o del archivo = 3.9 MB

m = 10: Tiempo de inserci√≥n = 33 segundos, Tama√±o del archivo = 3.3 MB

m = 25: Tiempo de inserci√≥n = 31 segundos, Tama√±o del archivo = 2.8 MB

m = 100: Tiempo de inserci√≥n = 28 segundos, Tama√±o del archivo = 2.6 MB

Como se puede observar, aumentar el valor de m mejora tanto el tiempo de inserci√≥n como el uso de espacio, debido a que se reducen las divisiones de nodos y se mejora la compactaci√≥n del √°rbol. Esto confirma que una mayor capacidad de fan-out en los nodos del B+ Tree puede resultar beneficiosa para datasets de tama√±o considerable.