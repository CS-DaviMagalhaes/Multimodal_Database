{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed52d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b3ceb",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Extraer los features de las imagenes de la carpeta utilizando opencv con SIFT.\n",
    "\n",
    "```keypoints, descriptors = sift.detectAndCompute(gray, None)```\n",
    "- keypoints almacena las coordenadas (x,y) de cada keypoint de la imagen (esquinas, manchas, cambios bruscos de intensidad, etc).\n",
    "- descriptors almacena los descriptores para cada keypoint de esa imagen (128 descriptores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb9b6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción/cargar descriptores y aplicar PCA (analisis del pca en la sección de Analisis)\n",
    "def generate_descriptors(dataset_path, n_components_pca, \n",
    "                         pca_model_path=\"../Image_descriptors/pca_model.pkl\", \n",
    "                         descriptors_path=\"../Image_descriptors/descriptors.npz\"):\n",
    "\n",
    "    if os.path.exists(pca_model_path) and os.path.exists(descriptors_path):\n",
    "        # Cargar descriptores y pca desde los archivos si es que ya fueron generados\n",
    "        pca = joblib.load(pca_model_path)\n",
    "        data = np.load(descriptors_path, allow_pickle=True)\n",
    "        reduced_descriptors = data[\"descriptors\"] # Descriptores\n",
    "        image_paths = data[\"filenames\"] # Nombre del archivo de cada array de descriptores\n",
    "        print(f\"{len(reduced_descriptors)} descriptores cargados\")\n",
    "    \n",
    "    else: \n",
    "        # Generar descriptores por primera vez\n",
    "        sift = cv2.SIFT_create()\n",
    "        extracted_descriptors = []\n",
    "        image_paths = [] # Paths de las imagenes de las que se pudo extraer descriptores\n",
    "\n",
    "        for filename in os.listdir(dataset_path):\n",
    "            file_path = os.path.join(dataset_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                img = cv2.imread(file_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "                if descriptors is not None:\n",
    "                    image_paths.append(os.path.splitext(filename)[0]) #guardar el nombre del archivo sin la extensión \".jpg\"\n",
    "                    extracted_descriptors.append(descriptors.astype(np.float32))\n",
    "\n",
    "        print(f\"Descriptores extraidos de {len(extracted_descriptors)} imagenes\")\n",
    "\n",
    "        # Combinar descriptores para entrenar pca\n",
    "        all_descriptors = np.vstack(list(extracted_descriptors))\n",
    "        pca = PCA(n_components=n_components_pca)\n",
    "        pca.fit(all_descriptors) #entrenar pca\n",
    "\n",
    "        # Aplicar PCA a los descriptores\n",
    "        reduced_descriptors = []\n",
    "        for d in extracted_descriptors:\n",
    "            reduced_descriptors.append(pca.transform(d).astype(np.float32))\n",
    "        \n",
    "        # Guardo en un archivo los descriptores con el nombre de la imagen y en otro archivo el objeto pca, para aplicar pca en las queries\n",
    "        reduced_descriptors = np.array(reduced_descriptors, dtype=object)\n",
    "        np.savez_compressed(descriptors_path, descriptors=reduced_descriptors, filenames=image_paths)\n",
    "        joblib.dump(pca, \"pca_model.pkl\") \n",
    "        print(f\"{len(reduced_descriptors)} descriptores generados\")\n",
    "\n",
    "    \n",
    "    print(f\"Varianza retenida: {pca.explained_variance_ratio_.sum():.2%}\") # Varianza retenida por el pca\n",
    "    return reduced_descriptors, image_paths, pca\n",
    "\n",
    "def apply_kmeans(descriptors, n_clusters):\n",
    "    # K-Means para construir el diccionario visual\n",
    "    if os.path.exists(\"kmeans_model.pkl\"):\n",
    "        kmeans = joblib.load(\"kmeans_model.pkl\")\n",
    "    else: \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\") #n_clusters con el que obtuvimos mejores resultados\n",
    "        kmeans.fit(np.vstack(descriptors))\n",
    "        joblib.dump(kmeans, \"kmeans_model.pkl\")\n",
    "\n",
    "    return kmeans\n",
    "\n",
    "def construct_bd_histograms(descriptors, kmeans):\n",
    "    # Construcción de histogramas por imagen\n",
    "    all_histograms = []\n",
    "    for descriptor in descriptors:\n",
    "        histogram = np.zeros(kmeans.n_clusters, dtype=int)\n",
    "\n",
    "        if descriptor is not None:\n",
    "            cluster_assignments = kmeans.predict(descriptor)\n",
    "            for idx in cluster_assignments:\n",
    "                histogram[idx] += 1\n",
    "\n",
    "        # Normalización\n",
    "        histogram = histogram.astype(float)\n",
    "        histogram /= np.sum(histogram) if np.sum(histogram) > 0 else 1\n",
    "        all_histograms.append(histogram)\n",
    "    \n",
    "    return all_histograms\n",
    "\n",
    "def create_query_histogram(query__path, kmeans, pca): \n",
    "    sift = cv2.SIFT_create()\n",
    "    img = cv2.imread(query__path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        print(f\"No keypoints found in image: {query__path}\")\n",
    "        return np.zeros(kmeans.n_clusters, dtype=float)\n",
    "\n",
    "    descriptors_reduced = pca.transform(descriptors) # Aplicar pca a la query\n",
    "    \n",
    "    # Calcular histograma de la query\n",
    "    histogram = np.zeros(kmeans.n_clusters, dtype=int)\n",
    "    if descriptors_reduced is not None:\n",
    "        cluster_assignments = kmeans.predict(descriptors_reduced)\n",
    "        for idx in cluster_assignments:\n",
    "            histogram[idx] += 1\n",
    "\n",
    "    # Normalización\n",
    "    histogram = histogram.astype(float)\n",
    "    histogram /= np.sum(histogram) if np.sum(histogram) > 0 else 1\n",
    "    return histogram\n",
    "\n",
    "def calcular_tf_idf(descriptors, all_histograms, kmeans):\n",
    "    N = len(descriptors) #equivalente a la cantidad de imagenes \n",
    "    all_histograms = np.array(all_histograms, dtype=np.float32) \n",
    "\n",
    "    tf = all_histograms  # Como ya normalizamos antes, el tf es el histograma\n",
    "\n",
    "    idf = []\n",
    "    for i in range(kmeans.n_clusters): #i es el índice del visual word\n",
    "        df = np.sum(all_histograms[:, i] > 0) # all_histograms > 0 me da una matriz de booleanos (si aparece el word o no en el doc)\n",
    "        idf.append(np.log(N / (df + 1e-8))) # Sumo constante chiquita para evitar división por cero\n",
    "\n",
    "    idf_np = np.array(idf, dtype=np.float32)\n",
    "    tf_idf = tf * idf_np # (num_imagenes, num_clusters). tf_idf[i][j] es la importancia del visual word j en la imagen i\n",
    "\n",
    "    return tf_idf, idf_np #retorno idf_np para poder aplicarlo a la query\n",
    "\n",
    "def knn_secuencial(query_hist, k, idf_np, all_histograms, image_paths):\n",
    "    # Aplicar TF-IDF al histograma de la query\n",
    "    query = query_hist * idf_np\n",
    "\n",
    "    heap = []\n",
    "    for i, hist in enumerate(all_histograms):\n",
    "        dot = np.dot(query, hist)\n",
    "        norm_query = np.linalg.norm(query)\n",
    "        norm_hist = np.linalg.norm(hist)\n",
    "\n",
    "        cosine_sim = 0\n",
    "        if norm_query != 0 and norm_hist != 0:\n",
    "            cosine_sim = dot / (norm_query * norm_hist)\n",
    "\n",
    "\n",
    "        heapq.heappush(heap, (cosine_sim, image_paths[i]))  \n",
    "\n",
    "        if len(heap) > k:\n",
    "            heapq.heappop(heap)  # eliminar el menos similar\n",
    "\n",
    "    # Mostrar resultados en orden descendente de similitud \n",
    "    top_k = sorted(heap, reverse=True)\n",
    "    return top_k\n",
    "\n",
    "def print_top_results(top_k): # Para que en los analisis de kmeans no imprima cada rato, separo los print\n",
    "    print(\"\\nTop imágenes más similares:\")\n",
    "    for sim, name in top_k:\n",
    "        print(f\"{name}: similitud = {sim:.4f}\")\n",
    "\n",
    "def show_top_similar_images(top_k, query_image_path, dataset_path):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    # Mostrar imagen de la query\n",
    "    img_query = cv2.imread(query_image_path)\n",
    "    img_query = cv2.cvtColor(img_query, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.subplot(1, len(top_k) + 1, 1)\n",
    "    plt.imshow(img_query)\n",
    "    plt.title(\"Query\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Mostrar las imágenes similares\n",
    "    for rank, (sim, filename) in enumerate(top_k, start=2):\n",
    "        img_path = os.path.join(dataset_path, filename + \".jpg\") \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        plt.subplot(1, len(top_k) + 1, rank)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Sim: {sim:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2bf15",
   "metadata": {},
   "source": [
    "### Teoría tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba82f9",
   "metadata": {},
   "source": [
    "Aplicar ponderación TF-IDF\n",
    "\n",
    "- Los documentos son las imagenes\n",
    "- Los words son los clusters, cada cluster es un visual word\n",
    "\n",
    "![Visual Histogram](../imgs/visual_hist.png)\n",
    "\n",
    "\n",
    "\n",
    "Para la imagen de la bici tengo un histograma, cuento cuantas veces aparece cada descriptor en esa imagen de la bici.\n",
    "\n",
    "El tf seria algo como [5/7, 1/7, 1/7, 0/7] donde 7 es el total de términos en la imagen (total de palabras en el documento)\n",
    "- tf = $\\frac{n_{id}}{n_d}$\n",
    "- idf = $log(\\frac{N}{n_i})$\n",
    "\n",
    "El df seria el número de imagenes donde el visual word i aparece (al menos una vez). *la palabra x aparece en y documentos*\n",
    "\n",
    "![TF-IDF](../imgs/tf_idf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10f7f4",
   "metadata": {},
   "source": [
    "Calcular Document frequency, ejemplo:\n",
    "```py\n",
    "histograms = np.array([\n",
    "  [3, 0, 1],   # Imagen 1\n",
    "  [0, 2, 0],   # Imagen 2\n",
    "  [1, 0, 5],   # Imagen 3\n",
    "])\n",
    "```\n",
    "- Visual word 0 aparece en las imagenes 1 y 3. Image 1 and 3.\n",
    "- Visual word 2 aparece en la imagen 2.\n",
    "- Visual word 3 aparece en las imagenes 1 y 3.\n",
    "\n",
    "```histograms > 0``` me da una matriz booleana. Si un visual word aparece en el documento (cluster) seria True:\n",
    "```py\n",
    "[\n",
    "  [True,  False, True ],\n",
    "  [False, True,  False],\n",
    "  [True,  False, True ]\n",
    "]\n",
    "```\n",
    "Luego con ```np.sum()```  sumo veo en cuantos documentos aparece cada visual word (cuenta los True).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f50d8",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIAR PATH A DONDE TIENES EL DATASET COMPLETO GUARDADO, o al path de los dataset chiquitos\n",
    "dataset_path = \"C:/Users/davie/Downloads/fashion_small/images/\" \n",
    "query_path = \"C:/Users/davie/Downloads/fashion_small/images/5730.jpg\" # imagen query\n",
    "\n",
    "# numero de componentes pca y clusters KMeans. En la sección \"análisis\" abajo hicimos un analisis para elegir esos valores\n",
    "n_components = 70 \n",
    "n_clusters = 250\n",
    "\n",
    "descriptors, image_paths, pca = generate_descriptors(dataset_path, n_components)\n",
    "kmeans = apply_kmeans(descriptors, n_clusters)\n",
    "all_histograms = construct_bd_histograms(descriptors, kmeans)\n",
    "tf_idf, idf = calcular_tf_idf(descriptors, all_histograms, kmeans)\n",
    "\n",
    "# Calcular resultados más similares\n",
    "k = 10\n",
    "query_histogram = create_query_histogram(query_path, kmeans, pca)\n",
    "top_k_results = knn_secuencial(query_histogram, k, idf, all_histograms, image_paths)\n",
    "print_top_results(top_k_results)\n",
    "\n",
    "show_top_similar_images(top_k_results, query_path, dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfdda56",
   "metadata": {},
   "source": [
    "### KNN con indexación invertida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc54669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b632e31",
   "metadata": {},
   "source": [
    "### Análisis PCA y KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142cb34f",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "Como son muchos datos y el vector de SIFT es grande podemos utilizar reducción de dimensionalidad. Hacemos un análisis para saber cuantas componentes usamos en el PCA. Utilizamos menos imagenes para ese analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9763940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "all_descriptors = []\n",
    "\n",
    "tiny_dataset_path = \"../data/fashion_small_1000/\" \n",
    "#Extraer descriptores\n",
    "image_filenames = []\n",
    "for filename in os.listdir(tiny_dataset_path):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        full_path = os.path.join(tiny_dataset_path, filename)\n",
    "        image_filenames.append(full_path)\n",
    "\n",
    "total = 0\n",
    "for file_path in image_filenames: \n",
    "    total += 1\n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        all_descriptors.append(descriptors)\n",
    "\n",
    "\n",
    "print(\"Total images: \", total)\n",
    "X = np.vstack(all_descriptors)  # Unir vectores en una matriz\n",
    "\n",
    "# Aplicar pca\n",
    "explained_variances = []\n",
    "components_range = range(10, 130, 10)  # 10 a 120, pasos de 10\n",
    "\n",
    "for n in components_range:\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X)\n",
    "    explained_var = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"Componentes: {n} varianza acumulada: {explained_var:f}.\")\n",
    "    explained_variances.append(explained_var)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(components_range, explained_variances, marker='o')\n",
    "plt.xlabel('numero de componentes')\n",
    "plt.ylabel('Varianza acumulada')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
